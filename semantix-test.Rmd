---
title: "semantix-test"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require(ggplot2)
require(data.table)
# require(party)
# require(varImp)
require(reticulate)
require(onehot)
```

## Introdução


## Perguntas

1. Qual profissão tem mais tendência a fazer um empréstimo? De qual tipo?
2. Fazendo uma relação entre número de contatos e sucesso da campanha quais
são os pontos relevantes a serem observados?
3. Baseando-se nos resultados de adesão desta campanha qual o número médio e
o máximo de ligações que você indica para otimizar a adesão?
4. O resultado da campanha anterior tem relevância na campanha atual?
5. Qual o fator determinante para que o banco exija um seguro de crédito?
6. Quais são as características mais proeminentes de um cliente que possua
empréstimo imobiliário?


## Carga dos dados

```{r}

bank = fread("datasets/bank-full.csv",
             colClasses = c(job='factor', marital='factor', education='factor',
                            default='factor', housing='factor', loan='factor',
                            contact='factor', day='factor', month='factor',
                            poutcome='factor', y='factor'))
```

## Descrição dos dados:

* _age_: idade do cliente (numeric)
* _job_ : tipo de emprego (categorical: "admin.","unknown","unemployed", "management", "housemaid", "entrepreneur", "student", "blue-collar", "self-employed", "retired", "technician", "services") 
* _marital_ : estado de relacionamento (casado/solteiro/divorciado) (categorical: "married", "divorced", "single"; nota: "divorced" pode ser divorciado(a) ou viúvo(a))
* _education_: nível de educação (categorical: "unknown", "secondary", "primary", "tertiary")
* _default_: se tem dívidas atrasadas (binary: "yes", "no")
* _balance_: saldo anual, em euros (numeric) 
* _housing_: se tem empréstimo imobiliário (binary: "yes", "no")
* _loan_: se tem empréstimo pessoal (binary: "yes", "no")
* _contact_: Meio usado para contato (categorical: "unknown", "telephone", "cellular") 
* _day_: Dia do mês do último contato (numeric)
* _month_: Mês do último contato (categorical: "jan", "feb", "mar", ..., "nov", "dec")
* _duration_: duração do último contato, em segundos (numeric)
* _campaign_: número de contatos feitos nesta campanha para este cliente (numeric, includes last contact)
* _pdays_: número de dias que passaram desde do último contato ao cliente em uma campanha anterior (numeric, -1 significa que não houve contato anterior)
* _previous_: número de contatos feitos antes dessa campanha a este cliente (numeric)
* _poutcome_: resultado deste usuário na ultima campanha de marketing (categorical: "unknown","other","failure","success")


## Resumo dos dados:

```{r}
  summary(bank)
```

Não parece haver muitos outliers ou dados danificados, com a exceção de algumas colunas. Consideramos como outliers, dados aonde há uma grande diferença entre Min e 1º quartil ou Max e 3ºquartil.

* duration: É comum que algumas ligações durem muito mais do que o normal, não temos motivos para descartar estes dados ou considerá-los seriamente anômalos.

* campaign: Parece excessivo que clientes tenham sido contactados até 63 vezes durante uma mesma campanha. Esse valor pode ser um possível erro.

* pdays: Também não é incomum de se esperar que tenha passado um longo tempo entre ligações de diferentes campanhas. O fato de que a maioria dos valores é '-1', que é um rotulo para 'sem contato prévio', distorce essa distribuição.

* previous: Possui um problema similar ao campo 'pdays', já que 'sem contato prévio' corresponde a 0.

*y: Vemos que o desbalanceamento no campo representando nossa _label_ é bem significativo, com apenas 8.5% das entradas sendo 'yes', e o restante sendo 'no'.
É importante que prestemos atenção nestes detalhes destes dados em análises futuras.


### Pergunta 1:

**Qual profissão tem mais tendência a fazer um empréstimo? De qual tipo?**


#### Análise numérica

Para responder essa pergunta, vamos primeiro analisar as colunas de profissões (job) e de resultados dos empréstimos (y), e a aceitação de cada um deles.

```{r}
ggplot(bank) + geom_bar(aes(x = job, fill = y), stat = 'count') +
             theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

Intuitivamente, vemos alguns tipos de empregados são bem mais contatados do que outros, como por exemplo, trabalhadores de escritório(blue-collar), gerentes, e técnicos. Também vemos que a taxa de aceitação aparenta ser baixa no geral, o que é esperado para marketing de massa.

Abaixo veremos com mais detalhes qual a taxa de aceitação para cada profissão:

```{r}
job.perc = bank[, .(.N, 
          yes.perc=sum(ifelse(y=='yes',1, 0))*100/.N, 
          no.perc=sum(ifelse(y=='no',1, 0))*100/.N
          ), by=.(job)]

ggplot(job.perc) + 
    geom_bar(aes(x = job, y = yes.perc),stat = 'identity') +
    theme(axis.text.x = element_text(angle = 90, hjust = 1))

```

Neste gráfico, fica claro que estudantes fazem um número maior de empréstimos, seguidos por pessoas aposentadas, apesar dos mesmos não serem tão contatados pelo banco, com estes respondendo nossa questão.


#### Análise preditiva

Como refoço a primeira parte, tentaramos aqui prever se um empréstimo foi realizado ou não usando apenas profissões. Para podermos verificar quais profissões são mais relevantes, usaremos o algoritimo de aprendizado _Random Forest_.

##### Preprocessamento

Para descobrir qual profissão tem maior relevância, precisamos desdobrar nossa coluna de profissões em várias features *one hot*, necessárias para o Random Forest processar corretamente, já que árvores de decisão só lidam com dados ordenados.

```{r}
oh_encoder = onehot(data.table(job=bank$job), max_levels = 20)
jobs_dt = data.table(predict(oh_encoder, data.table(job=bank$job)))
jobs_dt$y = bank$y
```

##### Encontrando melhor modelo

Nosso objetivo aqui não é encontrar um modelo viável para prever profissões, mas sim encontrar o modelo com a melhor precisão para aceitação do empréstimo ('sim'), já que estamos buscando que profissões tendem a aceitar a oferta.

```{r}
require(reticulate) #Reticulate is an API that enables the use of python modules on R
ensemble = import('sklearn.ensemble') #In this case, I'm using scikit-learn.
metrics = import('sklearn.metrics')

n_estimators = seq.int(from=5, to=50, by=1)
oob_precision = c()

for(n_estimator in n_estimators) {
  model = ensemble$RandomForestClassifier(n_estimators=as.integer(n_estimator), class_weight='balanced', oob_score=TRUE, random_state=as.integer(42))
  model = model$fit(jobs_dt[, 1:12], as.matrix(jobs_dt[, 13])[, 1])
  oob_decision = data.table(
                    apply(
                      model$oob_decision_function_, 1, FUN=which.max))
  names(oob_decision) = "pred"
  oob_decision$pred = as.integer(oob_decision$pred) == 2 #TRUE == yes, FALSE == no
  oob_decision$real = as.integer(jobs_dt$y) == 2

  oob_score = metrics$precision_score(oob_decision$real, oob_decision$pred) #precision for 'yes'

  oob_precision <- c(oob_precision, oob_score) #precision for 'yes'

}
oob_precision <- setNames(oob_precision, n_estimators)
```

##### Treinando o melhor modelo:
```{r}
opt_n_estimator = n_estimators[which.max(oob_precision)]
model =  ensemble$RandomForestClassifier(n_estimators=as.integer(opt_n_estimator),   class_weight='balanced', random_state=as.integer(42))
model$fit(jobs_dt[, 1:12], as.matrix(jobs_dt[, 13])[, 1])

```

##### Importância de cada profissão:

```{r}
importances = model$feature_importances_
importances = data.table(importance = importances,
                         job = factor(gsub('job=', '', names(jobs_dt[, 1:12]))))
```

##### Resultados

```{r}
ggplot(importances) +
  geom_bar(aes(x=job,y=importance), stat='identity') +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

No gráfico acima, vemos que trabalhadores manuais, estudantes e aposentados são os tipos de trabalho com maior importância na hora de se prever o resultado. Entretanto, isso não implica diretamente que estes trabalhos são os que têm maior tendência de fazer um empréstimo, já que eles podem influenciar a árvore de decisão tendo valor 1 (o que implica que esse trabalho tem tendência de aceitar a oferta) ou tendo valor 0 ( implicando que esse trabalho tem tendência de não aceitar a oferta), nos seus nós.

Analisando a estrutura de nossas árvores de decisão, vemos que o primeiro caso (valor 1), é valido para estudantes e aposentados, enquanto o segundo caso (valor 0), é valido para trabalhadores manuais. Isso implica que estudantes e aposentados têm maior tendência de aceitar a oferta, enquanto trabalhadores manuais têm menos chance de aceitá-la.


### Pergunta 2:

**Fazendo uma relação entre número de contatos e sucesso da campanha quais
são os pontos relevantes a serem observados?**

Similarmente a pergunta anterior, começaremos com uma demonstração dos dados relacionados

```{r}
ggplot(bank) + geom_bar(aes(x = factor(campaign), fill = y), stat = 'count') +
             labs(x="Qtd. de ligações", y="Total de aceites", fill="Aceitou?") +
             theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

Como constatamos anteriormente, vemos que há grupos de clientes que foram contatados em grande quantidade. Contudo, eles representam um grupo muito pequeno, com pouca relevância estatística. Também temos que considerar a baixa taxa de adesão dos usuários no geral (~11.7%). Para evitar influência destes grupos com poucos dados na nossa análise, usaremos somente grupos que possuam ao menos 100 usuários. 

```{r}
campaign.perc = bank[, .(.N, 
          yes.perc=sum(ifelse(y=='yes',1, 0))*100/.N, 
          no.perc=sum(ifelse(y=='no',1, 0))*100/.N
          ), by=.(campaign)]
```

Como resultado, o gráfico a seguir mostra o percentual de negócios fechados para diferentes quantidades de ligações recebidas. 

```{r}
ggplot(campaign.perc[N >= 100], aes(x = campaign, y = yes.perc)) + 
    geom_bar(stat = 'identity') +
    geom_smooth(color='black', method='lm') +
    labs(x="Qtd. de ligações", y="% de aceites")
```

No gráfico, vemos que há uma tendência de quem recebe menos ligações, fechar mais contratos. Isso é confirmado pela correlação de pearson entre número de ligações e taxas de aceite, que é negativa, com valor de `-0.7`.

```{r}
cor.test(campaign.perc$campaign, campaign.perc$yes.perc)
```

Novamente para explicitar melhor as diferenças, 

```{r}
ggplot(campaign.perc[N >= 100]) + 
    geom_bar(aes(x = campaign, y = scale(yes.perc)),stat = 'identity') +
    labs(x="Qtd. de ligações", y="% de aceites (escalada pela média)")
```


### Pergunta 3:

**Baseando-se nos resultados de adesão desta campanha qual o número médio e
o máximo de ligações que você indica para otimizar a adesão?**

Ainda baseado nos dados da pergunta anterior, as pessoas que recebem mais ligações ainda fecham contratos. Entretanto, estas ligações poderiam estar sendo utilizadas para ligar para outros potenciais clientes, que teriam mais chance de fechar contrato nas primeiras ligações. Então, a não ser em caso de exaustão de clientes viáveis, é interessante sempre tentar contactar novos clientes, com a média de ligações por cliente devendo ser próxima de 1.


Como vimos acima, é recomendado contactar a maior quantidade de clientes possível, então devemos manter a quantidade média de ligações baixa. Para estabelecer uma quantidade máximo de ligações, construímos o gráfico abaixo. Ele mostra os mesmos dados do gráfico da pergunta anterior, mas agora com os valores do eixo y escaladas em razão da sua distância para a média. O valor 0 representa a média, e cada unidade representa um desvio padrão. Vemos que 5 ligações é o último valor para o qual a porcentagem de aceites se mantêm acima da média. Com isso, estabelecemos 5 como um valor razoável para a quantidade máxima de ligações.


```{r}
ggplot(campaign.perc[N >= 100]) + 
    geom_bar(aes(x = campaign, y = scale(yes.perc)),stat = 'identity') +
    labs(x="Qtd. de ligações", y="% de aceites (escalada pela média)")
```

Um melhor detalhamento dos resultados obtidos se encontra na tabela abaixo.


```{r}
knitr::kable(setorder(campaign.perc[N >= 100], 'campaign'))
```


### Pergunta 4:

**O resultado da campanha anterior tem relevância na campanha atual?**

#### Análise numérica

Para respondermos essa pergunta, primeiro precisamos definir o que é relevância. Definieremos que alguma variável relacionada a campanha anterior é relevante se ela impactar de maneira significativa o resultado da campanha atual. Para determinarmos se esse impacto existe, relacionaremos as variáveis associadas a campanha anterior (pdays, previous, poutcome), com o resultado da campanha atual (y).

##### pdays:

Para verificarmos se há relação entre o número de dias desde do último contato e o resultado da campanha atual, compararemos o valor de pdays para resultados positivos e resultados negativos. Levaremos em consideração somente usuários que foram contatados em campanhas anteriores.

A comparação será realizada através de um teste t. Valores de p maiores ou iguais a 0.05 indicam que não há diferença significativa entre os grupos.

```{r}
t.test(bank[pdays != -1 & y=='yes']$pdays, bank[pdays != -1 & y=='no']$pdays)
```

Vemos que há sim uma diferença significativa neste caso. Pessoas que fecharam negócio tendem a ter sido contatadas a menos tempo pelo banco. Entretanto, a quantidade de dias desde do ultimo contato é alta em ambos os casos, com 192 dias para clientes que fecharam negócio vs. 234 dias para clientes que não fecharam, em média.


##### previous:

Aqui aplicaremos a mesma lógica usada em pdays para verificar se a quantidade de ligações recebida tem alguma associação com clientes que fecharam ou não negócio.

```{r}
t.test(bank[previous > 0 & y=='yes']$previous, bank[previous > 0 & y=='no']$previous)
```

Neste caso, não aparenta haver diferença significativa entre a quantidade de contatos recebidos em outras campanhas por clientes que fecharam ou não negócio. O que indica que a quantidade de ligações recebidas anteriormente não é um diferencial real neste caso.


##### poutcome:
Como neste caso estamos comparando duas variáveis discretas, não podemos nos utilizar de testes t. Aqui compararemos o resultado da campanha anterior em dois grupos de clientes: os que fecharam negócio nesta campanha ou não. Isso será feito através da diferença da concentração dos valores possíveis de poutcome nos dois grupos.

Aqui usaremos somente os valores 'failure' e 'success' de poutcome, já que eles são os únicos com uma semântica clara o suficiente para inferirmos resultados, além de indicarem que este usuário já participou de campanhas anteriores.

```{r}
      sort(
          prop.table(summary(bank[poutcome %in% c("failure", "success") & y=='yes']$poutcome)) -
          prop.table(summary(bank[poutcome %in% c("failure", "success") & y=='no']$poutcome)), 
        decreasing = TRUE) * 100

```
Aqui vemos que usuários que aceitaram a oferta nesta campanha tem muito mais chances de já terem a aceitado anteriormente, com 50% a mais de aceites anteriores por parte destes usuários. Realizaremos este experimento novamente, mas agora na 'direção oposta', ou seja, verificando a diferença de aceite atual baseado em aceites anteriores.

```{r}
      sort(
          prop.table(summary(bank[poutcome=='success']$y)) -
          prop.table(summary(bank[poutcome=='failure']$y)), 
        decreasing = TRUE) * 100

```

Assim confirmamos a tendência mostrada no teste anterior. Usuários que já aceitaram uma campanha anterior apresentam 52% a mais de aceite da campanha atual.


#### Análise Preditiva

No caso da análise preditiva, consideraremos uma variável relevante, se ela prevê corretamente o resultado da campanha atual. Para isso, compararemos tanto o impacto do da variável (poutcome) representando o resultado da campanha anterior quando comparado com outras variáveis, como comparar os resultados da campanha anterior entre si (success x failure).

Para tal, construiremos novamente um modelo de Florestas aleatórias para nos permitir a análise do impacto das variáveis no resultado.

##### Preprocessamento

Similarmente ao feito na pergunta 1, precisamos transformar nossas variáveis categóricas que não são ordernáveis para o formato 'onehot'. Transformaremos variáveis categóricas que são ordenáveis para inteiros.

```{r}
rf_bank = copy(bank)
rf_bank$day = as.integer(as.character(rf_bank$day))
rf_bank$month = sapply(rf_bank$month, function(x) grep(paste("(?i)", x, sep=""), month.abb))

oh_encoder = onehot(rf_bank[,1:16], max_levels = 100)

rf_bank = data.table(predict(oh_encoder, rf_bank[,1:16]))
rf_bank$y = bank$y
```

##### Encontrando melhor modelo

Nosso objetivo aqui não é encontrar um modelo viável para realizar previsões reais, mas sim encontrar o modelo com a melhor precisão para aceitação do empréstimo ('sim'), já que estamos buscando que profissões tendem a aceitar a oferta. O modelo escolhido poderá sofrer de _overfitting_, mas isso não é o problema, que que queremos que ele descreva nossos dados o mais precisamente possível.

Para aliviar com o fato de que há um forte desbalanço nos nossos alvos de predição (coluna y), balancearemos a importância de cada classe ('yes' e 'no') pelo inverso da sua frequência. Para medir as métricas necessárias para comparação entre modelos, usaremos a técnica OOB, específica ao Random Forest.

```{r}

best_rf <- function(X, y, metric_fun, n_estimators) {
  require(reticulate) #Reticulate is an API that enables the use of python modules on R
  ensemble = import('sklearn.ensemble') #In this case, I'm using scikit-learn.
  
  oob_results = c()
  
  for(n_estimator in n_estimators) {
    model = ensemble$RandomForestClassifier(n_estimators=as.integer(n_estimator), class_weight='balanced', oob_score=TRUE, random_state=as.integer(42))
    model = model$fit(X, as.matrix(y)[, 1])
    oob_decision = data.table(
                      apply(
                        model$oob_decision_function_, 1, FUN=which.max))
    names(oob_decision) = "pred"
    oob_decision$pred = as.integer(oob_decision$pred) == 2 #TRUE == yes, FALSE == no
    oob_decision$real = as.integer(y$y) == 2
  
    oob_score = metric_fun(oob_decision$real, oob_decision$pred)
    oob_results <- c(oob_results, oob_score)
  
  }
  
  oob_results <- setNames(oob_results, n_estimators)
  return(oob_results)
}

```


##### Treinando o melhor modelo:

```{r}
  rf_feature_importance <- function(X, y, metric_fun, n_estimators){
    ensemble = import('sklearn.ensemble')
    
    oob_metrics = best_rf(X, y, metric_fun, n_estimators)  
    
    opt_n_estimator = n_estimators[which.max(oob_metrics)]
    model =  ensemble$RandomForestClassifier(n_estimators=as.integer(opt_n_estimator),   class_weight='balanced', random_state=as.integer(42))
    model$fit(X, as.matrix(y)[, 1])
    importances = model$feature_importances_
    
    importances = data.table(importance = importances,
                           feature = names(X))
    return(importances)
}

```


##### Importância de cada profissão:

```{r}
  metrics = import('sklearn.metrics')
  X = 
  y = 
  metric_fun = 
  n_estimators = 
  
  importance = rf_feature_importance(X=rf_bank[, 1:40], 
                                     y=rf_bank[, 41], 
                                     n_estimators=seq.int(from=10, to=100, by=5), 
                                     metric_fun=metrics$precision_score)
```

#### Resultados

Removemos a feature de duração para melhor legibilidade do gráfico, já que ela, naturalmente é fortemente relacionada com o resultado, visto que pessoas que fecham negócio passam mais tempo para dar de conta dos detalhes.

```{r}
ggplot(importances[feature!='duration']) +
  geom_bar(aes(x=reorder(feature, -importance), y=importance), stat='identity') +
  labs(x='Variáveis', y='Escore de importância') +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

Vemos que os principais fatores que influenciam o usuário são seu saldo atual, sua idade, e a data (mes/dia) do contato. Em uma escala menor, vemos que fatores como: quantidade de contatos (campaign), explorada na Pergunta 3; contatos anteriores em sucedidos (poutcome=sucess), e a quantidade de dias desde do último contato (pdays). Os dois ultimos são relacionados com a nossa pergunta, e juntamente com o descoberto na análise numérica  nos mostram que uma *quantidade menor de dias desde do último contato*, e principalmente *o fato de um usuário já ter aceitado uma campanha anterior* são relevantes no resultado da campanha atual.


### Pergunta 5:

**Qual o fator determinante para que o banco exija um seguro de crédito?**

Não temos nos dados informações disponíveis quanto a se o cliente pagou o empréstimo ou não, então não podemos dizer com precisão o risco gerado por esse cliente. Mas segundo o senso comum, acredita-se podemos usar as variáveis abaixo para indicar possíveis mau pagadores.

* default: Um cliente com dívidas vencidas provavelmente tem dificuldades em pagar novas
* balance: Clientes sem dinheiro acumulado (saldo negativo) também podem ter dificuldade para pagar dividas
* housing, loan: Em conjunto com os outros campos, podemos indicar se um cliente têm dividas em excesso. Por exemplo, um cliente com um empresitmo pessoal e saldo negativo provavelmente está passando por dificuldades financeiras e não deve ser um bom pagador.


### Pergunta 6:

**Quais são as características mais proeminentes de um cliente que possua
empréstimo imobiliário?**

Primeiro, temos que dividir nossos usuários em clientes com e sem empréstimo imobiliário. Definiremos as caracteristicas proeminentes dos clientes com emprestimo, a partir da comparação destes com os clientes sem empréstimo

```{r}
  cli.imo = bank[housing=='yes']
  other.cli = bank[housing=='no']
```

Os dois conjuntos são grandes o suficiente para realizarmos comparações válidas, com `r nrow(cli.imo)` entradas para clientes com empréstimo e `r nrow(other.cli)` para clientes sem empréstimo. O mínimo necessário para fazermos comparações confiáveis seria de 381 (5% de intervalo de confiança, 95% de nível de confiança), calculado usando o link  a seguir: https://www.surveysystem.com/sscalc.htm#one

A partir disso compararemos as variáveis de cada um dos conjuntos, a partir de testes t, no caso de valores continuos, e subtraindo as porcentagens da presença de cada um dos tipos de elementos (com emprestimo - sem emprestímo) no caso de variáveis discretas.

Abaixo destacamos as principais descobertas a partir do descrito:

* Clientes com empréstimo imobiliário são mais novos do que clientes sem empréstimo, em média (38.8 anos x 43.1 anos).

* Clientes com empréstimo imobiliário têm mais chances de serem trabalhadores de escritório, com 14% a mais desses trabalhadores em comparação a clientes sem empréstimo

* Clientes com empréstimo imobiliário tem mais chances de possuírem educação secundária (10% a mais)

* Clientes com empréstimo imobiliário tem saldo bancário menor do que seus contrapartes, em média ($1175 x $1596)

* Estes clientes têm uma quantidade de empréstimo levemente maior do que seus contrapartes (3% a mais)

* Estranhamente, estes clientes tendem a receber mais ligações no mês de maio (40% a mais), e menos no mês de agosto(21% a menos), quando comparado com seus contrapartes.

* Finalmente estes clientes tendem a aceitar menos ofertas (9% a menos).


Uma descrição completa dos resultados dos testes encontra-se abaixo.

```{r}
for(name in names(cli.imo)){
  print(name)
  if(class(cli.imo[,get(name)]) != 'factor'){
    result = t.test(cli.imo[,get(name)], other.cli[,get(name)])
    print(sprintf("t=%.3f, p=%.3f, imo_mean(%s)=%.3f, noimo_mean(%s)=%.3f",
                 result$statistic, result$p.value, 
                 name, result$estimate[1], 
                 name, result$estimate[2]))
  }else{
    print(
      sort(
        prop.table(summary(cli.imo[,get(name)])) - prop.table(summary(other.cli[,get(name)])), decreasing = TRUE) * 100
      )
  }
  print("")
}

```


